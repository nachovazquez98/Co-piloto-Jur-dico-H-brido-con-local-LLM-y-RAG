# Co-piloto Jur√≠dico H√≠brido (v9.8)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=yellow)
![spaCy](https://img.shields.io/badge/spaCy-v3.0%2B-brightgreen?logo=spacy)
![Transformers](https://img.shields.io/badge/Transformers-HuggingFace-yellow?logo=huggingface)
![Ollama](https://img.shields.io/badge/Ollama-Local_LLM-blueviolet)
![ChromaDB](https://img.shields.io/badge/ChromaDB-Vector_DB-orange)

Este repositorio contiene el c√≥digo de un prototipo avanzado para un **Co-piloto Jur√≠dico H√≠brido**, un sistema de Generaci√≥n Aumentada por Recuperaci√≥n (RAG) dise√±ado para analizar precedentes legales (sentencias judiciales) de forma 100% local y privada.

El sistema es "h√≠brido" en dos sentidos:
1.  **Ejecuci√≥n H√≠brida:** Utiliza un modelo de embeddings para la *recuperaci√≥n* de documentos y un LLM local (`llama3.1:8b` servido por `Ollama`) para la *generaci√≥n* de an√°lisis.
2.  **Clasificaci√≥n H√≠brida:** Implementa un novedoso clasificador num√©rico (`classify_dynamically`) que combina la b√∫squeda sem√°ntica (Coseno) con m√©tricas l√©xicas (Jaccard, KEM) para categorizar la consulta del usuario, eliminando la necesidad de una llamada costosa al LLM en la etapa de filtrado.

## üöÄ Caracter√≠sticas Principales

* **100% Local y Privado:** Todo el pipeline, desde la indexaci√≥n hasta la generaci√≥n de informes, se ejecuta localmente. No se env√≠an datos a APIs externas, garantizando la confidencialidad.
* **Ingesta Paralelizada:** La Fase 1 (`fase1_procesar_pdfs`) utiliza `concurrent.futures.ProcessPoolExecutor` para procesar m√∫ltiples PDFs en paralelo, acelerando significativamente la creaci√≥n del corpus.
* **Clasificaci√≥n H√≠brida-Num√©rica:** Un clasificador r√°pido y ligero (`classify_dynamically`) que utiliza `spaCy` y `scikit-learn` para categorizar la consulta del usuario en una de las 1053 categor√≠as legales sin usar un LLM.
* **B√∫squeda Adaptativa:** El sistema primero intenta una "B√∫squeda Estricta" (filtrada por la categor√≠a predicha) y, si no encuentra suficientes resultados, autom√°ticamente realiza una "B√∫squeda Amplia" sem√°ntica (fallback).
* **Pipeline de Doble Control de Calidad (QC):**
    1.  **QC_1 (Relevancia de Contexto):** Un prompt de verificaci√≥n (`PROMPT_VERIFICACION_RELEVANCIA`) se asegura de que el *documento* recuperado sea contextualmente relevante (ej. distingue "lesiones en ri√±a" de "lesiones por violencia familiar").
    2.  **QC_2 (Anti-Alucinaci√≥n):** Un segundo prompt (`PROMPT_VERIFICACION_POST_REPORTE`) verifica que el *informe generado* por el LLM sea coherente con la consulta original (ej. descarta un informe sobre "fraude" si la consulta era sobre "lesiones").
* **Extracci√≥n Robusta con Fallback:** El sistema primero intenta una extracci√≥n estructurada (`PROMPT_EXTRACCION_PENAL`). Si falla (ej. debido a texto anonimizado `[ELIMINADO]`), reintenta autom√°ticamente con un prompt gen√©rico (`PROMPT_EXTRACCION_GENERICA_FALLBACK`) para maximizar la tasa de √©xito.
* **S√≠ntesis Comparativa Final:** En lugar de solo listar documentos, el sistema genera un resumen ejecutivo (`PROMPT_SINTESIS_FINAL`) que compara los 3 precedentes v√°lidos encontrados, ofreciendo un an√°lisis de valor agregado.

## ‚öôÔ∏è Stack Tecnol√≥gico

* **Servidor LLM:** `Ollama`
* **Modelo LLM:** `llama3.1:8b` (o cualquier modelo compatible con Ollama)
* **Base de Datos Vectorial:** `ChromaDB` (para almacenamiento persistente)
* **Modelo de Embeddings:** `sentence-transformers/all-mpnet-base-v2`
* **Procesamiento de PDF:** `PyPDF2`
* **Procesamiento de Texto y M√©tricas:** `spaCy` (lematizaci√≥n), `scikit-learn` (cosine_similarity)
* **Manejo de Datos:** `pandas`, `pyarrow` (para almacenamiento en Parquet)
* **Paralelizaci√≥n:** `concurrent.futures.ProcessPoolExecutor`

## üèõÔ∏è Arquitectura y Flujo de Trabajo

El sistema opera en tres fases principales:

### Fase 1: Ingesta y Procesamiento (Paralelizado)

1.  **Escanear:** El script escanea `PDF_DATABASE_PATH` en busca de archivos `.pdf`.
2.  **Procesar en Paralelo:** `fase1_procesar_pdfs` usa `ProcessPoolExecutor` para distribuir la carga de trabajo.
3.  **Extraer y Limpiar:** Cada proceso hijo (`process_single_pdf`) abre un PDF, aplica un muestreo estrat√©gico para documentos largos, y usa Regex (`RE_NOISE_F1`, `RE_STRUCTURAL_KEYWORDS_F1`) para extraer y limpiar el cuerpo legal del texto.
4.  **Parsear Metadatos:** Los metadatos (`materia_principal`, `delito_o_accion`) se extraen de la nomenclatura del nombre del archivo.
5.  **Guardar en Lotes:** Los datos limpios (ID, texto, metadatos) se guardan en archivos `.parquet` en el directorio `BATCH_TEMP_DIR`.

### Fase 2: Indexaci√≥n en la Base de Datos Vectorial

1.  **Cargar Modelo:** Se inicializa el modelo de embeddings (`all-mpnet-base-v2`) y se mueve a la GPU (CUDA) si est√° disponible.
2.  **Conectar a DB:** Se inicializa `chromadb.PersistentClient` y se crea (o limpia) la colecci√≥n `sentencias_judiciales`.
3.  **Procesar Lotes:** El script itera sobre los archivos `.parquet` de la Fase 1.
4.  **Generar Embeddings:** Los textos de cada lote se dividen en sub-lotes (`INDEXING_BATCH_SIZE = 50`) para generar los embeddings vectoriales sin sobrecargar la VRAM de la GPU.
5.  **Indexar:** Los embeddings, documentos (texto) y metadatos se cargan en `ChromaDB`.

### Fase 3: Inferencia RAG (El Co-piloto)

Este es el flujo de ejecuci√≥n principal para cada consulta del usuario:

1.  **Cargar Cach√©:** Carga las 1053 categor√≠as √∫nicas y sus embeddings pre-calculados (`rag_categories_cache7.json`, `rag_embeddings_cache7.npy`).
2.  **Clasificaci√≥n H√≠brida:** `classify_dynamically` identifica la mejor categor√≠a-filtro (ej. `PENAL robo-calificado...`) usando una f√≥rmula ponderada de Coseno, Jaccard, KEM y Concisi√≥n.
3.  **B√∫squeda Adaptativa:** `generate_multianalysis_report_from_rag` intenta una "B√∫squeda Estricta" en ChromaDB usando la categor√≠a como filtro `where`. Si falla, "relaja" la consulta y realiza una "B√∫squeda Amplia" sem√°ntica.
4.  **Bucle de Generaci√≥n (Doble QC + Fallback):**
    * El sistema itera sobre los 50 mejores candidatos (`RAG_NUM_RESULTS_TO_FETCH = 50`) hasta encontrar 3 v√°lidos (`RAG_NUM_RESULTS_DESIRED = 3`).
    * **Pasa por QC_1:** `PROMPT_VERIFICACION_RELEVANCIA` comprueba si el *contexto* del documento coincide (ej. "ri√±a de bar" vs "violencia familiar").
    * **Pasa por Extracci√≥n:** Intenta `PROMPT_EXTRACCION_PENAL`.
    * **Pasa por Fallback:** Si la extracci√≥n falla (ej. por texto anonimizado `[ELIMINADO]`), reintenta con `PROMPT_EXTRACCION_GENERICA_FALLBACK`.
    * **Pasa por QC_2:** `PROMPT_VERIFICACION_POST_REPORTE` comprueba que el *informe generado* no sea una alucinaci√≥n (ej. un informe de "fraude" en un documento de "lesiones").
5.  **S√≠ntesis Final:** Los 3 informes v√°lidos se env√≠an a `generate_final_synthesis`, que usa `PROMPT_SINTESIS_FINAL` para crear un resumen comparativo.
6.  **Entrega:** Se presenta al usuario la S√≠ntesis (respuesta principal) y el Ap√©ndice (los 3 informes detallados).

## üí° Hallazgos Clave y Robustez del Sistema

Durante las pruebas, se identificaron varios puntos de fallo que esta arquitectura (v9.8) est√° dise√±ada para manejar:

* **Problema: Datos Mal Etiquetados.**
    * **Hallazgo:** Un documento sobre "acta de nacimiento" estaba incorrectamente etiquetado como "robo calificado" en el nombre del archivo.
    * **Soluci√≥n:** El filtro **QC_1 (`PROMPT_VERIFICACION_RELEVANCIA`)** detect√≥ esta discrepancia contextual y descart√≥ el documento, evitando que contaminara los resultados.

* **Problema: Clasificaci√≥n Incorrecta.**
    * **Hallazgo:** La consulta sobre "ri√±a en un bar" fue clasificada err√≥neamente. Esto llev√≥ a la B√∫squeda Amplia, que recuper√≥ documentos sem√°nticamente similares pero contextualmente incorrectos (ej. "violencia familiar").
    * **Soluci√≥n:** El filtro **QC_1** (con su ejemplo expl√≠cito "ri√±a de bar vs. violencia familiar") detect√≥ y descart√≥ exitosamente estos falsos positivos.

* **Problema: Alucinaci√≥n del LLM.**
    * **Hallazgo:** En un caso, el sistema recuper√≥ un documento sobre "lesiones" (aprobado por QC_1), pero el LLM alucin√≥ y gener√≥ un informe sobre "fraude".
    * **Soluci√≥n:** El filtro **QC_2 (`PROMPT_VERIFICACION_POST_REPORTE`)** compar√≥ el informe generado ("fraude") con la consulta original ("lesiones") y descart√≥ el informe, previniendo una alucinaci√≥n grave.

* **Problema: Texto Anonimizado.**
    * **Hallazgo:** El documento m√°s relevante para la consulta de "ri√±a" (`lesiones-en-rina.pdf`) estaba lleno de texto `[ELIMINADO]`, lo que provoc√≥ que el `PROMPT_EXTRACCION_PENAL` fallara.
    * **Soluci√≥n:** La **l√≥gica de fallback** se activa, reintentando con `PROMPT_EXTRACCION_GENERICA_FALLBACK`. Los prompts de extracci√≥n actualizados ahora contienen instrucciones expl√≠citas para ignorar las marcas de anonimizaci√≥n y resumir la informaci√≥n visible.

## üîß Propuestas de Mejora (Trabajo Futuro)

1.  **Ingesta de Metadatos con IA:** El eslab√≥n m√°s d√©bil sigue siendo la dependencia de la nomenclatura de archivos. La Fase 1 deber√≠a mejorarse para usar un LLM (`PROMPT_CLASIFICAR_MATERIA`) que lea el contenido de cada PDF y *genere* los metadatos de forma fiable.
2.  **Ajuste de Pesos del Clasificador:** Los pesos del re-ranking h√≠brido (ej. `JACCARD_WEIGHT`) son heur√≠sticos. Se podr√≠an ajustar o entrenar en un conjunto de datos de prueba para mejorar la precisi√≥n de la clasificaci√≥n (Paso 2).
3.  **Integraci√≥n de OCR:** A√±adir `Tesseract` o `PyMuPDF` para manejar documentos que sean im√°genes escaneadas, aumentando la cantidad de datos procesables.
